{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6f15f5",
   "metadata": {},
   "source": [
    "# Taking the Images to Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf5e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0\n",
      "Collecting data for class 1\n",
      "Collecting data for class 2\n",
      "Collecting data for class 3\n",
      "Collecting data for class 4\n",
      "Collecting data for class 5\n",
      "Collecting data for class 6\n",
      "Collecting data for class 7\n",
      "Collecting data for class 8\n",
      "Collecting data for class 9\n",
      "Collecting data for class 10\n",
      "Collecting data for class 11\n",
      "Collecting data for class 12\n",
      "Collecting data for class 13\n",
      "Collecting data for class 14\n",
      "Collecting data for class 15\n",
      "Collecting data for class 16\n",
      "Collecting data for class 17\n",
      "Collecting data for class 18\n",
      "Collecting data for class 19\n",
      "Collecting data for class 20\n",
      "Collecting data for class 21\n",
      "Collecting data for class 22\n",
      "Collecting data for class 23\n",
      "Collecting data for class 24\n",
      "Collecting data for class 25\n",
      "Collecting data for class 26\n",
      "Collecting data for class 27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "number_of_classes = 28\n",
    "dataset_size = 1000\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "for j in range(number_of_classes):\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
    "\n",
    "    print('Collecting data for class {}'.format(j))\n",
    "\n",
    "    done = False\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Start collecting new images without overwriting existing ones\n",
    "    existing_files = os.listdir(os.path.join(DATA_DIR, str(j)))\n",
    "    existing_numbers = [int(f.split('.')[0]) for f in existing_files if f.endswith('.jpg') and f.split('.')[0].isdigit()]\n",
    "    counter = max(existing_numbers) + 1 if existing_numbers else 0\n",
    "\n",
    "    while counter < dataset_size + len(existing_numbers):\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        filename = os.path.join(DATA_DIR, str(j), f'{counter}.jpg')\n",
    "        cv2.imwrite(filename, frame)\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a4558",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af823419",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d003e8c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5adba6c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95099da9",
   "metadata": {},
   "source": [
    "# Creating The Dataset from Taken Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697517ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "\n",
    "f = open('data.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c27f01",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ee76f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d874ee3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc2e6e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e03e8",
   "metadata": {},
   "source": [
    "# Building The Classifier and training on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4567a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.98206278026906% of samples were classified correctly !\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dict = pickle.load(open('./data.pickle', 'rb'))\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples were classified correctly !'.format(score * 100))\n",
    "\n",
    "f = open('model.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3ab85",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113723d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2ef3e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc6082",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b2bba",
   "metadata": {},
   "source": [
    "# Testing the Model with Real-Time Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3394dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque, Counter\n",
    "\n",
    "# Load model\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Labels\n",
    "labels_dict = {i: chr(65 + i) for i in range(26)}\n",
    "labels_dict[26] = 'Space'\n",
    "labels_dict[27] = 'Backspace'  \n",
    "\n",
    "# Sentence tracking\n",
    "sentence = \"\"\n",
    "predictions_queue = deque(maxlen=20)\n",
    "last_added_char = \"\"\n",
    "last_time_added = time.time()\n",
    "ADD_LETTER_DELAY = 3.0  # seconds between letters\n",
    "\n",
    "# Scanning effect variables\n",
    "scan_start_time = 0\n",
    "scan_duration = 0.6  # seconds\n",
    "scanning = False\n",
    "\n",
    "# Draw bounding box\n",
    "def draw_camera_box(img, x1, y1, x2, y2, color=(0, 0, 255), thickness=3, corner_len=150, full_box=True):\n",
    "    if full_box:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    else:\n",
    "        cv2.line(img, (x1, y1), (x1 + corner_len, y1), color, thickness)\n",
    "        cv2.line(img, (x1, y1), (x1, y1 + corner_len), color, thickness)\n",
    "        cv2.line(img, (x2, y1), (x2 - corner_len, y1), color, thickness)\n",
    "        cv2.line(img, (x2, y1), (x2, y1 + corner_len), color, thickness)\n",
    "        cv2.line(img, (x1, y2), (x1 + corner_len, y2), color, thickness)\n",
    "        cv2.line(img, (x1, y2), (x1, y2 - corner_len), color, thickness)\n",
    "        cv2.line(img, (x2, y2), (x2 - corner_len, y2), color, thickness)\n",
    "        cv2.line(img, (x2, y2), (x2, y2 - corner_len), color, thickness)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_, y_ = [], []\n",
    "    ret, frame = cap.read()\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x = landmark.x\n",
    "                y = landmark.y\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            # بعد ما نجيب min/max مرة واحدة\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                data_aux.append(landmark.x - min(x_))\n",
    "                data_aux.append(landmark.y - min(y_))\n",
    "\n",
    "\n",
    "            x1 = int(min(x_) * W) - 20\n",
    "            y1 = int(min(y_) * H) - 20\n",
    "            x2 = int(max(x_) * W) + 20\n",
    "            y2 = int(max(y_) * H) + 20\n",
    "\n",
    "            prediction = model.predict([np.asarray(data_aux)])\n",
    "            predicted_character = labels_dict[int(prediction[0])]\n",
    "            predictions_queue.append(predicted_character)\n",
    "\n",
    "            most_common_char, count = Counter(predictions_queue).most_common(1)[0]\n",
    "\n",
    "            if count > 15 and (most_common_char != last_added_char or current_time - last_time_added > ADD_LETTER_DELAY):\n",
    "                if most_common_char == 'Space':\n",
    "                    sentence += ' '\n",
    "                elif most_common_char == 'Backspace':\n",
    "                    sentence = sentence[:-1]\n",
    "                else:\n",
    "                    sentence += most_common_char\n",
    "                last_added_char = most_common_char\n",
    "                last_time_added = current_time\n",
    "                scan_start_time = current_time\n",
    "                scanning = True\n",
    "\n",
    "            # Draw box\n",
    "            draw_camera_box(frame, x1, y1, x2, y2, color=(0, 0, 255))\n",
    "\n",
    "            # Scanning effect (moving green line)\n",
    "            if scanning and current_time - scan_start_time < scan_duration:\n",
    "                progress = (current_time - scan_start_time) / scan_duration\n",
    "                scan_y = int(y1 + progress * (y2 - y1))\n",
    "                cv2.line(frame, (x1, scan_y), (x2, scan_y), (0, 255, 0), 2)\n",
    "            else:\n",
    "                scanning = False\n",
    "\n",
    "            # Show predicted char\n",
    "            cv2.putText(frame, most_common_char, (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
    "\n",
    "    # Show sentence\n",
    "    cv2.rectangle(frame, (20, 400), (620, 450), (255, 255, 255), -1)\n",
    "    cv2.putText(frame, sentence, (30, 435), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Keyboard input\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        sentence = \"\"\n",
    "        last_added_char = \"\"\n",
    "    elif key == 32:  # Space key\n",
    "        sentence += ' '\n",
    "        last_added_char = \"\"\n",
    "        predictions_queue.clear() \n",
    "    elif key == ord('z'):  # Backspace\n",
    "        if sentence:\n",
    "            sentence = sentence[:-1]\n",
    "            last_added_char = \"\"\n",
    "            predictions_queue.clear()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931dab6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'TTS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XttsConfig\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Xtts\n\u001b[0;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m XttsConfig()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'TTS'"
     ]
    }
   ],
   "source": [
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "\n",
    "config = XttsConfig()\n",
    "config.load_json(\"config.json\")\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(config, checkpoint_dir=\"dvae.pth\", eval=True)\n",
    "model.cuda()\n",
    "\n",
    "outputs = model.synthesize(\n",
    "    \"It took me quite a long time to develop a voice and now that I have it I am not going to be silent.\",\n",
    "    config,\n",
    "    speaker_wav=\"g.wav\",\n",
    "    gpt_cond_len=3,\n",
    "    language=\"en\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
